# 生成更多手势识别数据

+ [生成更多手势识别数据](#生成更多手势识别数据)
  + [0. 前言](#0-前言)
  + [1. 视频生成流程](#1-视频生成流程)
    + [1.1. 前景](#11-前景)
    + [1.2. 背景](#12-背景)
    + [1.3. 融合](#13-融合)

## 0. 前言
+ 总目标：为手势识别模型获取更多数据。
+ 思路：通过去背景/换背景获取更多手势识别数据。
  + 新的手势识别数据分为前景与背景。
  + 前景通过录制简单背景视频+去背景来实现。
  + 背景通过录制任意视频来实现。

## 1. 视频生成流程

### 1.1. 前景
+ 目标：获取去除背景的纯手势图片。
+ 获取流程：
  + 第一步：请各位大哥拍摄简单背景的手势视频。
    + 要求每个视频只有一个手势，动作开始/结束前后有些许空隙。
    + 如果一段视频有多个动作，需要手动拆分。可以通过 ffmpeg 实现，参考 `scripts/split_video.dat`。
    + 每一类动作的视频放在一个同一个文件夹内。
  + 第二步：通过图像分割算法提取手部。
    + 要先看下分割结果如何，不好的视频要剔除。
+ 输出：一个文件夹，该文件夹有若干子文件夹，每个子文件夹代表一类动作，包含若干只包含一个动作的小视频。
+ 文件目录结构：
  + 所有数据保存在 `/path/to/ar/generate/foreground` 中。
  + 包含若干子文件夹，如 `raw` 表示原始文件，其他文件夹以类别名称命名，如 `ok`/`left`/`right`/`close`。

### 1.2. 背景
+ 目标：获取若干小视频。
+ 功能：将一个视频拆分为多个短视频。
  + 脚本：`src/split_video.py`
  + 

### 1.3. 融合